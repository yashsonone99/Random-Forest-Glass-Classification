# -*- coding: utf-8 -*-
"""Random forest.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1u4ehIx2d9QpbqqZDVYpyoQP6vcK228Bt
"""

# Cell 1 — Imports & load CSV (handles extra blank rows)
import os
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.ensemble import RandomForestClassifier, BaggingClassifier, AdaBoostClassifier, GradientBoostingClassifier
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report, confusion_matrix

sns.set(style="whitegrid")
pd.options.display.float_format = '{:.4f}'.format

# Path to your uploaded file (update if needed)
file_path = "/content/glass.csv"   # or "/mnt/data/glass.csv"

if not os.path.exists(file_path):
    raise FileNotFoundError(f"{file_path} not found. Upload the CSV to the notebook environment.")

# Read CSV
df_raw = pd.read_csv(file_path, header=0)
print("Raw shape:", df_raw.shape)
display(df_raw.head(6))

# Cell 2 — Clean dataset: drop rows that are all NaN / mostly NaN, ensure numeric types
df = df_raw.copy()

# If there are rows with all NaNs or Type is NaN, drop them
# Drop rows where all feature columns are NaN
df = df.dropna(how='all').reset_index(drop=True)

# If 'Type' column exists but has NaNs, drop those rows too
if 'Type' in df.columns:
    df = df[df['Type'].notna()].reset_index(drop=True)

# Convert numeric columns to proper dtype (coerce errors)
num_cols = ['RI','Na','Mg','Al','Si','K','Ca','Ba','Fe','Type']
# keep only columns that actually exist in df
num_cols = [c for c in num_cols if c in df.columns]

for c in num_cols:
    df[c] = pd.to_numeric(df[c], errors='coerce')

# Drop any remaining rows that contain NaN in all key numeric columns
df = df.dropna(subset=num_cols).reset_index(drop=True)

# Convert Type to integer labels
df['Type'] = df['Type'].astype(int)

print("Cleaned shape:", df.shape)
print("Columns:", df.columns.tolist())
print("\nFirst 5 rows:")
display(df.head())
print("\nMissing values per column:")
print(df.isnull().sum())

# Cell 3 — EDA: summary stats, duplicates, distribution
print("Dataset info:")
print(df.info())

print("\nStatistical summary:")
display(df.describe().T)

# Check duplicates
print("\nDuplicate rows count:", df.duplicated().sum())

# Target distribution
print("\nTarget (Type) value counts:")
print(df['Type'].value_counts().sort_index())

plt.figure(figsize=(8,4))
sns.countplot(x='Type', data=df, palette='tab10')
plt.title("Glass Type Distribution")
plt.xlabel("Type")
plt.ylabel("Count")
plt.show()

# Cell 4 — Visualizations: histograms, boxplots and correlation heatmap
numeric_cols = [c for c in df.columns if df[c].dtype in [np.float64, np.int64] and c != 'Type']

# Histograms
df[numeric_cols].hist(figsize=(12,9), bins=20)
plt.suptitle("Feature Distributions")
plt.tight_layout(rect=[0,0,1,0.96])
plt.show()

# Boxplots (first 6 numeric)
for c in numeric_cols[:6]:
    plt.figure(figsize=(6,2.5))
    sns.boxplot(x=df[c])
    plt.title(f"Boxplot — {c}")
    plt.show()

# Correlation heatmap
plt.figure(figsize=(10,8))
sns.heatmap(df[numeric_cols + ['Type']].corr(), annot=True, fmt=".2f", cmap='coolwarm', square=False)
plt.title("Correlation Matrix")
plt.show()

# Cell 5 — Preprocessing: prepare X and y, scale features, split
X = df.drop(columns=['Type'])
y = df['Type']

# Scale numeric features
scaler = StandardScaler()
X_scaled = pd.DataFrame(scaler.fit_transform(X), columns=X.columns)

# Stratify if possible
stratify_arg = y if y.value_counts().min() >= 2 else None

X_train, X_test, y_train, y_test = train_test_split(
    X_scaled, y, test_size=0.25, random_state=42, stratify=stratify_arg
)

print("Train shape:", X_train.shape, "Test shape:", X_test.shape)
print("Train class distribution:\n", y_train.value_counts())
print("Test class distribution:\n", y_test.value_counts())

# Note on imbalance:
print("\nIf your classes are imbalanced, consider using SMOTE (imblearn) or class_weight in models.")

# Cell 6 — Baseline Random Forest
rf = RandomForestClassifier(n_estimators=200, random_state=42)
rf.fit(X_train, y_train)
y_pred = rf.predict(X_test)

def print_eval(y_true, y_pred):
    print("Accuracy:", accuracy_score(y_true, y_pred))
    print("Precision (weighted):", precision_score(y_true, y_pred, average='weighted', zero_division=0))
    print("Recall (weighted):", recall_score(y_true, y_pred, average='weighted', zero_division=0))
    print("F1-score (weighted):", f1_score(y_true, y_pred, average='weighted', zero_division=0))
    print("\nClassification report:\n", classification_report(y_true, y_pred, zero_division=0))
    cm = confusion_matrix(y_true, y_pred)
    plt.figure(figsize=(6,4))
    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')
    plt.xlabel("Predicted")
    plt.ylabel("Actual")
    plt.title("Confusion Matrix")
    plt.show()

print("Baseline Random Forest evaluation on test set:")
print_eval(y_test, y_pred)

# Cell 7 — Hyperparameter tuning (small grid to be safe)
from sklearn.model_selection import GridSearchCV, StratifiedKFold

min_count = np.min(y_train.value_counts())
n_splits = 3 if min_count >= 3 else 2
cv = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)

param_grid = {
    'n_estimators': [100, 200],
    'max_depth': [None, 6, 10],
    'min_samples_split': [2, 5],
    'min_samples_leaf': [1, 2]
}

grid = GridSearchCV(RandomForestClassifier(random_state=42), param_grid, cv=cv, scoring='accuracy', n_jobs=-1, verbose=1)
grid.fit(X_train, y_train)

best_rf = grid.best_estimator_
print("Best params:", grid.best_params_)
y_pred_best = best_rf.predict(X_test)
print("Tuned RF performance:")
print_eval(y_test, y_pred_best)

# Cell 8 — Bagging and Boosting methods comparison (robust to sklearn version)
from sklearn.ensemble import BaggingClassifier, AdaBoostClassifier, GradientBoostingClassifier
import inspect

# Helper to create a BaggingClassifier compatible with current sklearn
def make_bagging_with_estimator(estimator, n_estimators=10, random_state=42):
    # Prefer the 'estimator' argument; fall back to 'base_estimator' if necessary.
    sig = inspect.signature(BaggingClassifier.__init__)
    if 'estimator' in sig.parameters:
        return BaggingClassifier(estimator=estimator, n_estimators=n_estimators, random_state=random_state)
    else:
        # older sklearn versions
        return BaggingClassifier(base_estimator=estimator, n_estimators=n_estimators, random_state=random_state)

# Build models
try:
    bagging = make_bagging_with_estimator(RandomForestClassifier(n_estimators=50, random_state=42), n_estimators=10, random_state=42)
except Exception as e:
    print("Bagging construction failed:", e)
    # fallback: use simple Bagging with default base estimator (DecisionTree) to proceed
    bagging = BaggingClassifier(n_estimators=10, random_state=42)

adaboost = AdaBoostClassifier(n_estimators=100, random_state=42)
gb = GradientBoostingClassifier(n_estimators=100, random_state=42)

models = {
    'RandomForest (tuned)': best_rf,
    'Bagging (RF base)': bagging,
    'AdaBoost (DT base)': adaboost,
    'GradientBoosting': gb
}

results = {}
for name, model in models.items():
    print("\n---", name)
    try:
        model.fit(X_train, y_train)
        y_pred_m = model.predict(X_test)
        # reuse print_eval() from earlier cell
        print_eval(y_test, y_pred_m)
        results[name] = accuracy_score(y_test, y_pred_m)
    except Exception as e:
        print(f"Model {name} failed with error: {e}")

print("\nSummary of test accuracies:")
for k, v in results.items():
    print(f"{k}: {v:.4f}")

# Cell 9 — Save the best RF model
import joblib
joblib.dump(best_rf, "best_random_forest_glass.pkl")
print("Saved best model to best_random_forest_glass.pkl")